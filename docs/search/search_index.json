{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"airflow-indexima \u00b6 WORK IN PROGRESS !! Versions following Semantic Versioning Overview \u00b6 Indexima Airflow integration based on pyhive. Setup \u00b6 Requirements \u00b6 Python 3.6+ Installation \u00b6 Install this library directly into an activated virtual environment: $ pip install airflow-indexima or add it to your Poetry project: $ poetry add airflow-indexima Usage \u00b6 After installation, the package can imported: $ python >>> import airflow_indexima >>> airflow_indexima.__version__ See Api documentation Example \u00b6 a simple query \u00b6 from airflow_indexima import IndeximaQueryRunnerOperator ... with dag : ... op = IndeximaQueryRunnerOperator ( task_id = 'my-task-id' , sql_query = 'DELETE FROM Client WHERE GRPD = 1' , indexima_conn_id = 'my-indexima-connection' ) ... a load into indexima \u00b6 from airflow_indexima import IndeximaLoadDataOperator ... with dag : ... op = IndeximaLoadDataOperator ( task_id = 'my-task-id' , indexima_conn_id = 'my-indexima-connection' , target_table = 'Client' , source_select_query = 'select * from dsi.client' , truncate = True , load_path_uri = 'jdbc:redshift://my-private-instance.com:5439/db_client?ssl=true&user=airflow-user&password=XXXXXXXX' ) ... License \u00b6 The MIT License (MIT) Contributing \u00b6 See Contributing","title":"Home"},{"location":"#airflow-indexima","text":"WORK IN PROGRESS !! Versions following Semantic Versioning","title":"airflow-indexima"},{"location":"#overview","text":"Indexima Airflow integration based on pyhive.","title":"Overview"},{"location":"#setup","text":"","title":"Setup"},{"location":"#requirements","text":"Python 3.6+","title":"Requirements"},{"location":"#installation","text":"Install this library directly into an activated virtual environment: $ pip install airflow-indexima or add it to your Poetry project: $ poetry add airflow-indexima","title":"Installation"},{"location":"#usage","text":"After installation, the package can imported: $ python >>> import airflow_indexima >>> airflow_indexima.__version__ See Api documentation","title":"Usage"},{"location":"#example","text":"","title":"Example"},{"location":"#a-simple-query","text":"from airflow_indexima import IndeximaQueryRunnerOperator ... with dag : ... op = IndeximaQueryRunnerOperator ( task_id = 'my-task-id' , sql_query = 'DELETE FROM Client WHERE GRPD = 1' , indexima_conn_id = 'my-indexima-connection' ) ...","title":"a simple query"},{"location":"#a-load-into-indexima","text":"from airflow_indexima import IndeximaLoadDataOperator ... with dag : ... op = IndeximaLoadDataOperator ( task_id = 'my-task-id' , indexima_conn_id = 'my-indexima-connection' , target_table = 'Client' , source_select_query = 'select * from dsi.client' , truncate = True , load_path_uri = 'jdbc:redshift://my-private-instance.com:5439/db_client?ssl=true&user=airflow-user&password=XXXXXXXX' ) ...","title":"a load into indexima"},{"location":"#license","text":"The MIT License (MIT)","title":"License"},{"location":"#contributing","text":"See Contributing","title":"Contributing"},{"location":"changelog/","text":"1.0.0 (2019-11-27) \u00b6 initial project structure based on geronimo-iia/template-python add Hook implementation add Simple Operator add pyhive, ... configure documentation add a way to customize credentials retreival (with a prepare connection function handler)","title":"Release Notes"},{"location":"changelog/#100-2019-11-27","text":"initial project structure based on geronimo-iia/template-python add Hook implementation add Simple Operator add pyhive, ... configure documentation add a way to customize credentials retreival (with a prepare connection function handler)","title":"1.0.0 (2019-11-27)"},{"location":"code_of_conduct/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00b6 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00b6 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00b6 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at jguibert@gmail.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of Conduct"},{"location":"code_of_conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"code_of_conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at jguibert@gmail.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"contributing/","text":"Contributing \u00b6 This project is based on Geronimo-iaa's Python Template . This is a cookiecutter template for a typical Python library following modern packaging conventions. It utilizes popular libraries alongside Make and Graphviz to fully automate all development and deployment tasks. Setup \u00b6 Requirements \u00b6 Make: macOS: $ xcode-select --install Linux: https://www.gnu.org/software/make Windows: https://mingw.org/download/installer Pyenv: https://github.com/pyenv/pyenv#installation Pyenv will manage all our python version. Python: $ pyenv install 3.7.3 Note for MacOS 10.14 user : SDKROOT = /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk MACOSX_DEPLOYMENT_TARGET = 10 .14 pyenv install 3 .7.3 Poetry: https://poetry.eustace.io/docs/#installation Poetry will manage our dependencies and create our virtual environment for us. Graphviz: macOS: $ brew install graphviz Linux: https://graphviz.org/download Windows: https://graphviz.org/download Needed to generate UML documentation To confirm these system dependencies are configured correctly: $ make doctor Installation \u00b6 Install project dependencies into a virtual environment: $ make install Note: - this target create a dummy file .install . The makefile rule depends on pyproject.toml and poetry.lock file - if for whatever reason, you have to force installation, just remove this .install file and execute a make install Development Tasks \u00b6 Manual \u00b6 Run the tests: $ make test Run static analysis: $ make check Build the documentation: $ make docs Automatic \u00b6 Keep all of the above tasks running on change: $ make watch In order to have OS X notifications, brew install terminal-notifier . Integration With Visual Studio Code \u00b6 Even if we use fabulous tool like pyenv, poetry, ... at the end, we just want to go on, and code. So here, few detail of my installation. .bashrc # init pyenv with default python version if command -v pyenv 1 >/dev/null 2 > & 1 ; then eval \" $( pyenv init - ) \" fi # add poetry in path export PATH = \" $HOME /.poetry/bin: $PATH \" # Add Visual Studio Code (code) export PATH = \" $PATH :/Applications/Visual Studio Code.app/Contents/Resources/app/bin\" poetry configuration: all is let with default settings.virtualenvs.create = true settings.virtualenvs.in-project = false settings.virtualenvs.path = \"/Users/xxxx/Library/Caches/pypoetry/virtualenvs\" repositories = {} As now, i cannot have a working system with 'settings.virtualenvs.in-project' set to true or 'settings.virtualenvs.path' setted with a custom path. How Launch Visual Studio Code within virtual environment created by poetry ? After do a make install , you have to do: poetry shell code . poetry shell will activate project virtual environment. Continuous Integration \u00b6 The CI server will report overall build status: $ make ci Release Tasks \u00b6 Release to PyPI: $ make upload","title":"Contributing"},{"location":"contributing/#contributing","text":"This project is based on Geronimo-iaa's Python Template . This is a cookiecutter template for a typical Python library following modern packaging conventions. It utilizes popular libraries alongside Make and Graphviz to fully automate all development and deployment tasks.","title":"Contributing"},{"location":"contributing/#setup","text":"","title":"Setup"},{"location":"contributing/#requirements","text":"Make: macOS: $ xcode-select --install Linux: https://www.gnu.org/software/make Windows: https://mingw.org/download/installer Pyenv: https://github.com/pyenv/pyenv#installation Pyenv will manage all our python version. Python: $ pyenv install 3.7.3 Note for MacOS 10.14 user : SDKROOT = /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk MACOSX_DEPLOYMENT_TARGET = 10 .14 pyenv install 3 .7.3 Poetry: https://poetry.eustace.io/docs/#installation Poetry will manage our dependencies and create our virtual environment for us. Graphviz: macOS: $ brew install graphviz Linux: https://graphviz.org/download Windows: https://graphviz.org/download Needed to generate UML documentation To confirm these system dependencies are configured correctly: $ make doctor","title":"Requirements"},{"location":"contributing/#installation","text":"Install project dependencies into a virtual environment: $ make install Note: - this target create a dummy file .install . The makefile rule depends on pyproject.toml and poetry.lock file - if for whatever reason, you have to force installation, just remove this .install file and execute a make install","title":"Installation"},{"location":"contributing/#development-tasks","text":"","title":"Development Tasks"},{"location":"contributing/#manual","text":"Run the tests: $ make test Run static analysis: $ make check Build the documentation: $ make docs","title":"Manual"},{"location":"contributing/#automatic","text":"Keep all of the above tasks running on change: $ make watch In order to have OS X notifications, brew install terminal-notifier .","title":"Automatic"},{"location":"contributing/#integration-with-visual-studio-code","text":"Even if we use fabulous tool like pyenv, poetry, ... at the end, we just want to go on, and code. So here, few detail of my installation. .bashrc # init pyenv with default python version if command -v pyenv 1 >/dev/null 2 > & 1 ; then eval \" $( pyenv init - ) \" fi # add poetry in path export PATH = \" $HOME /.poetry/bin: $PATH \" # Add Visual Studio Code (code) export PATH = \" $PATH :/Applications/Visual Studio Code.app/Contents/Resources/app/bin\" poetry configuration: all is let with default settings.virtualenvs.create = true settings.virtualenvs.in-project = false settings.virtualenvs.path = \"/Users/xxxx/Library/Caches/pypoetry/virtualenvs\" repositories = {} As now, i cannot have a working system with 'settings.virtualenvs.in-project' set to true or 'settings.virtualenvs.path' setted with a custom path. How Launch Visual Studio Code within virtual environment created by poetry ? After do a make install , you have to do: poetry shell code . poetry shell will activate project virtual environment.","title":"Integration With Visual Studio Code"},{"location":"contributing/#continuous-integration","text":"The CI server will report overall build status: $ make ci","title":"Continuous Integration"},{"location":"contributing/#release-tasks","text":"Release to PyPI: $ make upload","title":"Release Tasks"},{"location":"documentation/","text":"Documentation \u00b6 Note on documentation generation. Tooling \u00b6 mkdocs to generate web site pydocmd (based on mkdocs) to generate API doc from docstyle pyreverse to generate uml diagram Documentation folder \u00b6 under mkdocs folder: 'docs' which keep handle writed doc file, 'docs/api' api generated files folder 'docs/uml' uml gererated diagrams folder 'mkdocs.yaml': configuration file for mkdocs tool Makefile targets \u00b6 Main target: 'docs' call 'mkdocs-site': call 'mkdocs-uml': Generate UML Diagram call 'mkdocs-api': Generate API documentation call 'mkdocs-md': Copy standard document Build web site with mkdocs tool move generated website content into '/docs' folder in order to expose with github page project Cleaning target: '.clean-docs' - Remove all temp files Extract from Makefile \u00b6 DOCS_PATH := mkdocs/docs SITE_PATH := mkdocs/site mkdocs-uml: $(DOCS_PATH)/uml ## Generate UML Diagram $(DOCS_PATH)/uml: $(MODULES) @ mkdir -p $(DOCS_PATH)/uml @ $(RUN) pyreverse $(PACKAGE) -p $(PACKAGE) -a 1 -f ALL -o png --ignore tests @ mv -f packages_$(PACKAGE).png $(DOCS_PATH)/uml/packages.png @ mv -f classes_$(PACKAGE).png $(DOCS_PATH)/uml/classes.png mkdocs-api: $(DOCS_PATH)/api ## Generate API documentation $(DOCS_PATH)/api: $(MODULES) @ mkdir -p $(DOCS_PATH)/api @ cd $(DOCS_PATH)/api; \\ PYTHONPATH=$(shell pwd); \\ $(RUN) pydocmd simple $(PACKAGE)+ > index.md # Add here all other package generation # PYTHONPATH=$(shell pwd) is a workaround to https://github.com/NiklasRosenstein/pydoc-markdown/issues/30 MK_FILES = $(DOCS_PATH)/index.md $(DOCS_PATH)/license.md $(DOCS_PATH)/changelog.md $(DOCS_PATH)/code_of_conduct.md mkdocs-md: $(MK_FILES) # Copy standard document $(DOCS_PATH)/index.md: README.md @ cp -f README.md $(DOCS_PATH)/index.md $(DOCS_PATH)/license.md: LICENSE.md @ cp -f LICENSE.md $(DOCS_PATH)/license.md $(DOCS_PATH)/changelog.md: CHANGELOG.md @ cp -f CHANGELOG.md $(DOCS_PATH)/changelog.md $(DOCS_PATH)/code_of_conduct.md: CODE_OF_CONDUCT.md @ cp -f CODE_OF_CONDUCT.md $(DOCS_PATH)/code_of_conduct.md mkdocs-site: mkdocs/mkdocs.yml mkdocs-uml mkdocs-api mkdocs-md ## Build Documentation Site @ cd mkdocs; \\ $(RUN) mkdocs build @ rm -rf docs/ @ mv mkdocs/site docs/ .clean-docs: ## remove all generated files @ rm -rf mkdocs/site @ rm -rf $(DOCS_PATH)/uml @ rm -rf $(DOCS_PATH)/api @ rm -rf $(DOCS_PATH)/index.md @ rm -rf $(DOCS_PATH)/license.md @ rm -rf $(DOCS_PATH)/changelog.md @ rm -rf $(DOCS_PATH)/code_of_conduct.md docs: mkdocs-site ## Generate documentation and UML","title":"Documentation"},{"location":"documentation/#documentation","text":"Note on documentation generation.","title":"Documentation"},{"location":"documentation/#tooling","text":"mkdocs to generate web site pydocmd (based on mkdocs) to generate API doc from docstyle pyreverse to generate uml diagram","title":"Tooling"},{"location":"documentation/#documentation-folder","text":"under mkdocs folder: 'docs' which keep handle writed doc file, 'docs/api' api generated files folder 'docs/uml' uml gererated diagrams folder 'mkdocs.yaml': configuration file for mkdocs tool","title":"Documentation folder"},{"location":"documentation/#makefile-targets","text":"Main target: 'docs' call 'mkdocs-site': call 'mkdocs-uml': Generate UML Diagram call 'mkdocs-api': Generate API documentation call 'mkdocs-md': Copy standard document Build web site with mkdocs tool move generated website content into '/docs' folder in order to expose with github page project Cleaning target: '.clean-docs' - Remove all temp files","title":"Makefile targets"},{"location":"documentation/#extract-from-makefile","text":"DOCS_PATH := mkdocs/docs SITE_PATH := mkdocs/site mkdocs-uml: $(DOCS_PATH)/uml ## Generate UML Diagram $(DOCS_PATH)/uml: $(MODULES) @ mkdir -p $(DOCS_PATH)/uml @ $(RUN) pyreverse $(PACKAGE) -p $(PACKAGE) -a 1 -f ALL -o png --ignore tests @ mv -f packages_$(PACKAGE).png $(DOCS_PATH)/uml/packages.png @ mv -f classes_$(PACKAGE).png $(DOCS_PATH)/uml/classes.png mkdocs-api: $(DOCS_PATH)/api ## Generate API documentation $(DOCS_PATH)/api: $(MODULES) @ mkdir -p $(DOCS_PATH)/api @ cd $(DOCS_PATH)/api; \\ PYTHONPATH=$(shell pwd); \\ $(RUN) pydocmd simple $(PACKAGE)+ > index.md # Add here all other package generation # PYTHONPATH=$(shell pwd) is a workaround to https://github.com/NiklasRosenstein/pydoc-markdown/issues/30 MK_FILES = $(DOCS_PATH)/index.md $(DOCS_PATH)/license.md $(DOCS_PATH)/changelog.md $(DOCS_PATH)/code_of_conduct.md mkdocs-md: $(MK_FILES) # Copy standard document $(DOCS_PATH)/index.md: README.md @ cp -f README.md $(DOCS_PATH)/index.md $(DOCS_PATH)/license.md: LICENSE.md @ cp -f LICENSE.md $(DOCS_PATH)/license.md $(DOCS_PATH)/changelog.md: CHANGELOG.md @ cp -f CHANGELOG.md $(DOCS_PATH)/changelog.md $(DOCS_PATH)/code_of_conduct.md: CODE_OF_CONDUCT.md @ cp -f CODE_OF_CONDUCT.md $(DOCS_PATH)/code_of_conduct.md mkdocs-site: mkdocs/mkdocs.yml mkdocs-uml mkdocs-api mkdocs-md ## Build Documentation Site @ cd mkdocs; \\ $(RUN) mkdocs build @ rm -rf docs/ @ mv mkdocs/site docs/ .clean-docs: ## remove all generated files @ rm -rf mkdocs/site @ rm -rf $(DOCS_PATH)/uml @ rm -rf $(DOCS_PATH)/api @ rm -rf $(DOCS_PATH)/index.md @ rm -rf $(DOCS_PATH)/license.md @ rm -rf $(DOCS_PATH)/changelog.md @ rm -rf $(DOCS_PATH)/code_of_conduct.md docs: mkdocs-site ## Generate documentation and UML","title":"Extract from Makefile"},{"location":"license/","text":"The MIT License (MIT) Copyright \u00a9 2019, Jerome Guibert Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"api/","text":"airflow_indexima \u00b6 airflow-indexima definition. This root module expose: IndeximaHook PrepareConnectionHandler IndeximaHookBasedOperator IndeximaQueryRunnerOperator IndeximaLoadDataOperator airflow_indexima.hook \u00b6 Indexima hook module definition. IndeximaHook \u00b6 IndeximaHook ( self , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Indexima hook implementation. This implementation can be used as a context manager like this: with IndeximaHook ( ... ) as hook : hook . run ( 'select ...' ) This implementation can be customized with a prepare_connection function which must have this profile: Callable[[Connection], Connection] (alias PrepareConnectionHandler) In this handler you could retreive credentials from other backeng like aws ssm. get_conn \u00b6 IndeximaHook . get_conn ( self ) -> pyhive . hive . Connection Return a hive connection. get_records \u00b6 IndeximaHook . get_records ( self , sql : str ) Execute query and return curror. (alias of run method) run \u00b6 IndeximaHook . run ( self , sql : str ) Execute query and return curror. commit \u00b6 IndeximaHook . commit ( self , tablename : str ) Execute a simple commit on table. rollback \u00b6 IndeximaHook . rollback ( self , tablename : str ) Execute a simple rollback on table. airflow_indexima.operator \u00b6 Indexima operators module definition. IndeximaHookBasedOperator \u00b6 IndeximaHookBasedOperator ( self , task_id : str , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Our base class for indexima operator. ui_color \u00b6 str(object='') -> str str(bytes_or_buffer[, encoding[, errors]]) -> str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object. str () (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'. IndeximaHook \u00b6 IndeximaHookBasedOperator . IndeximaHook ( self , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Indexima hook implementation. This implementation can be used as a context manager like this: with IndeximaHook ( ... ) as hook : hook . run ( 'select ...' ) This implementation can be customized with a prepare_connection function which must have this profile: Callable[[Connection], Connection] (alias PrepareConnectionHandler) In this handler you could retreive credentials from other backeng like aws ssm. get_hook \u00b6 IndeximaHookBasedOperator . get_hook ( self ) -> airflow_indexima . hook . IndeximaHook Return a configured IndeximaHook instance. IndeximaQueryRunnerOperator \u00b6 IndeximaQueryRunnerOperator ( self , task_id : str , sql_query : str , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) A simple query executor. template_fields \u00b6 tuple() -> empty tuple tuple(iterable) -> tuple initialized from iterable's items If the argument is a tuple, the return value is the same object. execute \u00b6 IndeximaQueryRunnerOperator . execute ( self , context ) Execute sql query. Parameters context : dag context IndeximaLoadDataOperator \u00b6 IndeximaLoadDataOperator ( self , task_id : str , indexima_conn_id : str , target_table : str , source_select_query : str , load_path_uri : str , truncate : bool = False , truncate_sql : Union [ str , NoneType ] = None , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Redshift to Indexima with mode full (truncate and import). Operations: 1. truncate target_table (false per default) 2. load source_select_query into target_table using redshift_user_name credential 3. commit/rollback target_table All fields ('target_table', 'load_path_uri', 'source_select_query', 'truncate_sql') support airflow macro. template_fields \u00b6 tuple() -> empty tuple tuple(iterable) -> tuple initialized from iterable's items If the argument is a tuple, the return value is the same object.","title":"API"},{"location":"api/#airflow_indexima","text":"airflow-indexima definition. This root module expose: IndeximaHook PrepareConnectionHandler IndeximaHookBasedOperator IndeximaQueryRunnerOperator IndeximaLoadDataOperator","title":"airflow_indexima"},{"location":"api/#airflow_indeximahook","text":"Indexima hook module definition.","title":"airflow_indexima.hook"},{"location":"api/#indeximahook","text":"IndeximaHook ( self , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Indexima hook implementation. This implementation can be used as a context manager like this: with IndeximaHook ( ... ) as hook : hook . run ( 'select ...' ) This implementation can be customized with a prepare_connection function which must have this profile: Callable[[Connection], Connection] (alias PrepareConnectionHandler) In this handler you could retreive credentials from other backeng like aws ssm.","title":"IndeximaHook"},{"location":"api/#get_conn","text":"IndeximaHook . get_conn ( self ) -> pyhive . hive . Connection Return a hive connection.","title":"get_conn"},{"location":"api/#get_records","text":"IndeximaHook . get_records ( self , sql : str ) Execute query and return curror. (alias of run method)","title":"get_records"},{"location":"api/#run","text":"IndeximaHook . run ( self , sql : str ) Execute query and return curror.","title":"run"},{"location":"api/#commit","text":"IndeximaHook . commit ( self , tablename : str ) Execute a simple commit on table.","title":"commit"},{"location":"api/#rollback","text":"IndeximaHook . rollback ( self , tablename : str ) Execute a simple rollback on table.","title":"rollback"},{"location":"api/#airflow_indeximaoperator","text":"Indexima operators module definition.","title":"airflow_indexima.operator"},{"location":"api/#indeximahookbasedoperator","text":"IndeximaHookBasedOperator ( self , task_id : str , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Our base class for indexima operator.","title":"IndeximaHookBasedOperator"},{"location":"api/#ui_color","text":"str(object='') -> str str(bytes_or_buffer[, encoding[, errors]]) -> str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object. str () (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.","title":"ui_color"},{"location":"api/#indeximahook_1","text":"IndeximaHookBasedOperator . IndeximaHook ( self , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Indexima hook implementation. This implementation can be used as a context manager like this: with IndeximaHook ( ... ) as hook : hook . run ( 'select ...' ) This implementation can be customized with a prepare_connection function which must have this profile: Callable[[Connection], Connection] (alias PrepareConnectionHandler) In this handler you could retreive credentials from other backeng like aws ssm.","title":"IndeximaHook"},{"location":"api/#get_hook","text":"IndeximaHookBasedOperator . get_hook ( self ) -> airflow_indexima . hook . IndeximaHook Return a configured IndeximaHook instance.","title":"get_hook"},{"location":"api/#indeximaqueryrunneroperator","text":"IndeximaQueryRunnerOperator ( self , task_id : str , sql_query : str , indexima_conn_id : str , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) A simple query executor.","title":"IndeximaQueryRunnerOperator"},{"location":"api/#template_fields","text":"tuple() -> empty tuple tuple(iterable) -> tuple initialized from iterable's items If the argument is a tuple, the return value is the same object.","title":"template_fields"},{"location":"api/#execute","text":"IndeximaQueryRunnerOperator . execute ( self , context ) Execute sql query. Parameters context : dag context","title":"execute"},{"location":"api/#indeximaloaddataoperator","text":"IndeximaLoadDataOperator ( self , task_id : str , indexima_conn_id : str , target_table : str , source_select_query : str , load_path_uri : str , truncate : bool = False , truncate_sql : Union [ str , NoneType ] = None , auth : str = 'CUSTOM' , prepare_connection : Union [ Callable [[ airflow . models . Connection ], airflow . models . Connection ], NoneType ] = None , * args , ** kwargs ) Redshift to Indexima with mode full (truncate and import). Operations: 1. truncate target_table (false per default) 2. load source_select_query into target_table using redshift_user_name credential 3. commit/rollback target_table All fields ('target_table', 'load_path_uri', 'source_select_query', 'truncate_sql') support airflow macro.","title":"IndeximaLoadDataOperator"},{"location":"api/#template_fields_1","text":"tuple() -> empty tuple tuple(iterable) -> tuple initialized from iterable's items If the argument is a tuple, the return value is the same object.","title":"template_fields"}]}